{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58533de-1b35-4321-81ff-d250a3752c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppanta/puru_proj/proj_v0/hints6_v0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import base_configs, deps, tr_va_te_split\n",
    "from utils import tr_va_te_split\n",
    "from utils.helpers import dir_helpers, rw_csv_helpers, feature_distr_helpers, feature_transform_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06f03b1-e12d-44b3-a23d-48a01912077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, math\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05238c2f-47e8-4d33-b6f4-ec343b0936ef",
   "metadata": {},
   "source": [
    "### 0 Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28a230e-5761-4726-81bb-05d4d324599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/ppanta/puru_proj/proj_v0/hints6_v0/ip/3_cleanedEncoded/hints6_7_cleaned_encoded.csv\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Shape: (10581, 26)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "All columns: ['FreqGoProvider', 'Deaf', 'MedConditions_Diabetes', 'MedConditions_HighBP', 'MedConditions_HeartCondition', 'MedConditions_LungDisease', 'MedConditions_Depression', 'AverageTimeSitting', 'EverHadCancer', 'Age', 'BirthGender', 'BMI', 'PHQ4', 'WeeklyMinutesModerateExercise', 'AvgDrinksPerWeek', 'GeneralHealth_Excellent', 'GeneralHealth_VeryGood', 'GeneralHealth_Good', 'GeneralHealth_Fair', 'GeneralHealth_Poor', 'smokeStat_Current', 'smokeStat_Former', 'smokeStat_Never', 'eCigUse_Current', 'eCigUse_Former', 'eCigUse_Never']\n"
     ]
    }
   ],
   "source": [
    "df_hints6 = \"ip/3_cleanedEncoded/hints6_public_filtered_v1_cleaned_encoded.csv\"\n",
    "df_hints7 = \"ip/3_cleanedEncoded/....csv\"\n",
    "df_hints6_7 = \"ip/3_cleanedEncoded/hints6_7_cleaned_encoded.csv\"\n",
    "df_orig = rw_csv_helpers.read_csv_file(df_hints6_7, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6719b3e-babe-4a16-8a3d-3a4e8c871e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for column 'MedConditions_HeartCondition' (only 0 and 1):\n",
      "MedConditions_HeartCondition\n",
      "0    9573\n",
      "1    1008\n",
      "Name: count, dtype: int64\n",
      "Total (0/1 only): 10581\n"
     ]
    }
   ],
   "source": [
    "counts = feature_distr_helpers.count01(df_orig.copy(), \"MedConditions_HeartCondition\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032186b-7d2f-4272-9bf4-b6dc86e6230c",
   "metadata": {},
   "source": [
    "### 1 Train - Validation - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f71dcb8-7c8b-4fab-9dea-568a58d29460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig.copy()\n",
    "target_col = \"MedConditions_HeartCondition\"\n",
    "CONFIGS = base_configs.get_base_configs()\n",
    "\n",
    "X = df_orig.drop(columns=[target_col])\n",
    "y = df_orig[target_col]\n",
    "\n",
    "result = tr_va_te_split.data_preprocessing(\n",
    "    CONFIGS=CONFIGS,\n",
    "    verbose=0,       # 0, 1, or 2\n",
    "    X=X, y=y,\n",
    "    balance_method=\"adasyn\",  # or 'smote', 'smoteenn', 'none'\n",
    "    balance_kwargs={\"n_neighbors\": 5}  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df2753-ab0c-44a9-bb42-9ad6cd98dd6b",
   "metadata": {},
   "source": [
    "### 2 Train - Validation - Test value assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc80352-7ab5-4a1d-84c1-47bfaf32f678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:            X = (6348, 25),      y = (6348,)\n",
      "X_train_res shape:        X = (11494, 25),  y = (11494,)\n",
      "X_val shape:              X = (2116, 25),        y = (2116,)\n",
      "X_test shape:             X = (2117, 25),       y = (2117,)\n",
      "X_train_res_scaled shape: X = (11494, 25)\n",
      "X_val_scaled shape:       X = (2116, 25)\n",
      "X_test_scaled shape:      X = (2117, 25)\n",
      "features length:          n = 25\n"
     ]
    }
   ],
   "source": [
    "print_result = feature_distr_helpers.print_shapes_and_features(result, verbose = 1)\n",
    "\n",
    "# Value assignments for further calculations\n",
    "X_train_res_scaled = result['X_train_res_scaled']\n",
    "X_val_scaled       = result['X_val_scaled']\n",
    "X_test_scaled      = result['X_test_scaled']\n",
    "\n",
    "X_train     = result['X_train']\n",
    "X_train_res = result['X_train_res']\n",
    "X_val       = result['X_val']\n",
    "X_test      = result['X_test']\n",
    "\n",
    "y_train     = result['y_train']\n",
    "y_train_res = result['y_train_res']\n",
    "y_val       = result['y_val']\n",
    "y_test      = result['y_test']\n",
    "\n",
    "features    = result['features']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05d86d-9288-42a2-a80c-64d9464ca636",
   "metadata": {},
   "source": [
    "### 3 Random forest Train-Validate-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf959a48-2d38-4c18-bd85-fa68340bd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pipeline_rf as pipeline_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f886c11-7aca-4363-bd05-9702ad8be00e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils.pipeline_rf' has no attribute 'run_rf_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_rf, results_rf \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_rf_pipeline\u001b[49m(\n\u001b[1;32m      2\u001b[0m     X_train_res_scaled, y_train_res,\n\u001b[1;32m      3\u001b[0m     X_val_scaled, y_val,\n\u001b[1;32m      4\u001b[0m     X_test_scaled, y_test,\n\u001b[1;32m      5\u001b[0m     features,\n\u001b[1;32m      6\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     threshold_strategy\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#\"balanced_accuracy\", #\"f1\", #\"cost\",\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'utils.pipeline_rf' has no attribute 'run_rf_pipeline'"
     ]
    }
   ],
   "source": [
    "model_rf, results_rf = pipeline_rf.run_rf_pipeline(\n",
    "    X_train_res_scaled, y_train_res,\n",
    "    X_val_scaled, y_val,\n",
    "    X_test_scaled, y_test,\n",
    "    features,\n",
    "    class_weight=\"balanced\",\n",
    "    threshold_strategy= \"f1\" #\"balanced_accuracy\", #\"f1\", #\"cost\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46684b31-fce1-4087-b819-8781ae54e647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379ba66c-676f-4875-afcc-99698d7091bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7800616649537513, 'balanced_accuracy': np.float64(0.7441109852774632), 'f1': 0.37058823529411766, 'precision': 0.252, 'recall': 0.7, 'roc_auc': np.float64(0.8001635837422927), 'avg_precision': np.float64(0.31520548198724685)}\n",
      "\n",
      "=== Logistic Regression Metrics ===\n",
      "      accuracy  balanced_accuracy      f1  precision  recall  roc_auc  avg_precision\n",
      "val     0.7729             0.7170  0.3481     0.2379  0.6484   0.7691         0.2594\n",
      "test    0.7801             0.7441  0.3706     0.2520  0.7000   0.8002         0.3152\n",
      "\n",
      "Chosen threshold (from VAL): 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_sweep': 'op/2_ml_predict/lr_run_001/lr_val_sweep_20251015_144449.csv',\n",
       " 'test_sweep': 'op/2_ml_predict/lr_run_001/lr_test_sweep_20251015_144449.csv',\n",
       " 'val_metrics': 'op/2_ml_predict/lr_run_001/lr_val_metrics_20251015_144449.csv',\n",
       " 'test_metrics': 'op/2_ml_predict/lr_run_001/lr_test_metrics_20251015_144449.csv',\n",
       " 'combined_metrics': 'op/2_ml_predict/lr_run_001/lr_combined_metrics_20251015_144449.csv',\n",
       " 'val_report': 'op/2_ml_predict/lr_run_001/lr_val_report_20251015_144449.txt',\n",
       " 'test_report': 'op/2_ml_predict/lr_run_001/lr_test_report_20251015_144449.txt'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in your notebook\n",
    "from utils.ml_lr import run_lr_pipeline_compat, export_lr_artifacts\n",
    "\n",
    "model_lr, results_lr = run_lr_pipeline_compat(\n",
    "    X_train_res_scaled, y_train_res,\n",
    "    X_val_scaled, y_val,\n",
    "    X_test_scaled, y_test,\n",
    "    features,\n",
    "    class_weight=\"balanced\",\n",
    "    threshold_strategy=\"f1\",\n",
    ")\n",
    "print(results_lr[\"test\"][\"metrics\"])\n",
    "\n",
    "export_lr_artifacts(results_lr, outdir=\"op/2_ml_predict/lr_run_001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6a982-8a3c-4a66-a946-9de63cdfb19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d1648c-5883-4ba3-b3c0-835049843277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Metrics ===\n",
      "      accuracy  balanced_accuracy      f1  precision  recall  roc_auc  avg_precision\n",
      "val     0.7729             0.7170  0.3481     0.2379  0.6484   0.7691         0.2594\n",
      "test    0.7801             0.7441  0.3706     0.2520  0.7000   0.8002         0.3152\n",
      "\n",
      "Chosen threshold (from VAL): 0.2000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "outdir = f\"op/2_ml_predict/lr_run_{ts}\"\n",
    "\n",
    "paths = export_lr_artifacts(\n",
    "    results_lr,\n",
    "    outdir=outdir,\n",
    "    prefix=\"lr\",\n",
    "    timestamp=ts,\n",
    "    include_preds=True,\n",
    "    print_metrics=True   # <-- prints val & test metrics to console\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90958839-eb42-418f-bb73-5b9f6df193a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble weights (LR, RF): [0.9287 0.0713] sum= 1.0\n",
      "Chosen threshold (validation): 0.29\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The '.style' accessor requires jinja2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5700/98330341.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0msummary_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_show\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0msummary_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_show\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;31m# 6) Pretty print (notebook Styler or console tabulate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m \u001b[0mprint_or_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;31m# 7) (Optional) Export to CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;31m# summary_val.to_csv(\"validation_summary.csv\", index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5700/98330341.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df_val, df_tst)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_or_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_tst\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m\"\"\"Display nicely in notebooks; otherwise print with tabulate or fallback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VALIDATION (threshold chosen here)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TEST (evaluated at the same threshold)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# console-friendly pretty print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5700/98330341.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, caption)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{:.4f}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"fc\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{:.0f}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"TN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"FP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"FN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"TP\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     s = (\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mset_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mset_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text-align\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"center\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/puru_proj/proj_v0/hints6_v0/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6317\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6318\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6319\u001b[0m         ):\n\u001b[1;32m   6320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/puru_proj/proj_v0/hints6_v0/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m         \"\"\"\n\u001b[1;32m   1446\u001b[0m         \u001b[0;31m# Raise AttributeError so that inspect works even if jinja2 is not installed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mhas_jinja2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jinja2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_jinja2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The '.style' accessor requires jinja2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStyler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The '.style' accessor requires jinja2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_score, recall_score,\n",
    "    f1_score, balanced_accuracy_score, matthews_corrcoef, brier_score_loss,\n",
    "    log_loss, confusion_matrix\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Pretty table helpers\n",
    "# ============================================================\n",
    "def _is_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        return \"IPKernelApp\" in get_ipython().config\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def style_summary(df: pd.DataFrame, caption: str = \"\"):\n",
    "    \"\"\"Return a styled DataFrame with nice formatting for notebooks.\"\"\"\n",
    "    # Columns where \"higher is better\" (we'll color the max)\n",
    "    higher_better = [\n",
    "        \"ROC_AUC\", \"PR_AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\",\n",
    "        \"Balanced_Accuracy\", \"MCC\"\n",
    "    ]\n",
    "    # Columns where \"lower is better\"\n",
    "    lower_better = [\n",
    "        \"Brier\", \"LogLoss\", \"ExpectedCost\", \"CostPerCase\", \"FP\", \"FN\"\n",
    "    ]\n",
    "\n",
    "    # Round numeric cols\n",
    "    fmt = {col: \"{:.4f}\" for col in df.columns if df[col].dtype.kind in \"fc\"}\n",
    "    fmt.update({col: \"{:.0f}\" for col in [\"TN\",\"FP\",\"FN\",\"TP\"] if col in df.columns})\n",
    "\n",
    "    s = (\n",
    "        df.style\n",
    "        .set_caption(caption)\n",
    "        .format(fmt)\n",
    "        .set_properties(**{\"text-align\": \"center\"})\n",
    "        .set_table_styles([\n",
    "            {\"selector\":\"caption\", \"props\":[(\"caption-side\",\"top\"),(\"font-weight\",\"bold\"),(\"font-size\",\"110%\")]},\n",
    "            {\"selector\":\"th\", \"props\":[(\"text-align\",\"center\"),(\"font-weight\",\"bold\")]},\n",
    "            {\"selector\":\"td\", \"props\":[(\"padding\",\"6px 10px\")]}\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Highlight best values\n",
    "    for col in higher_better:\n",
    "        if col in df.columns:\n",
    "            s = s.highlight_max(subset=[col], color=\"#d2f5d2\")\n",
    "    for col in lower_better:\n",
    "        if col in df.columns:\n",
    "            s = s.highlight_min(subset=[col], color=\"#d2f5d2\")\n",
    "\n",
    "    return s\n",
    "\n",
    "def print_or_display(df_val: pd.DataFrame, df_tst: pd.DataFrame):\n",
    "    \"\"\"Display nicely in notebooks; otherwise print with tabulate or fallback.\"\"\"\n",
    "    if _is_notebook():\n",
    "        from IPython.display import display\n",
    "        display(style_summary(df_val, \"VALIDATION (threshold chosen here)\"))\n",
    "        display(style_summary(df_tst, \"TEST (evaluated at the same threshold)\"))\n",
    "    else:\n",
    "        # console-friendly pretty print\n",
    "        try:\n",
    "            from tabulate import tabulate\n",
    "            print(\"\\nVALIDATION (threshold chosen here)\")\n",
    "            print(tabulate(df_val, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "            print(\"\\nTEST (evaluated at the same threshold)\")\n",
    "            print(tabulate(df_tst, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "        except Exception:\n",
    "            # plain fallback\n",
    "            print(\"\\nVALIDATION (threshold chosen here)\")\n",
    "            print(df_val.to_string(index=False))\n",
    "            print(\"\\nTEST (evaluated at the same threshold)\")\n",
    "            print(df_tst.to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# Core helpers\n",
    "# ============================================================\n",
    "def proj_simplex(v):\n",
    "    \"\"\"Project vector v onto the probability simplex {w >= 0, sum(w)=1}.\"\"\"\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "    rho = np.nonzero(u * np.arange(1, len(u)+1) > (cssv - 1))[0][-1]\n",
    "    theta = (cssv[rho] - 1) / (rho + 1.0)\n",
    "    return np.maximum(v - theta, 0.0)\n",
    "\n",
    "def solve_simplex_brier(P, y, iters=1500, lr=0.5, seed=42):\n",
    "    \"\"\"\n",
    "    Learn convex weights that minimize Brier score on validation.\n",
    "    P: (n_val, k) matrix of validation probabilities (one column per model)\n",
    "    y: (n_val,) array of true labels {0,1}\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    k = P.shape[1]\n",
    "    w = np.ones(k) / k  # start uniform\n",
    "    for _ in range(iters):\n",
    "        grad = (2.0 / len(y)) * P.T.dot(P.dot(w) - y)\n",
    "        w = proj_simplex(w - lr * grad)\n",
    "    return w\n",
    "\n",
    "def sweep_thresholds(y_true, y_prob, grid=None):\n",
    "    if grid is None: grid = np.linspace(0, 1, 101)\n",
    "    rows = []\n",
    "    for t in grid:\n",
    "        y_pred = (y_prob >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        n = len(y_true)\n",
    "        rows.append({\n",
    "            \"thr\": t,\n",
    "            \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "            \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "            \"acc\": (tn+tp)/n,\n",
    "            \"bacc\": balanced_accuracy_score(y_true, y_pred),\n",
    "            \"fp\": fp, \"fn\": fn\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def find_best_threshold(y_true, y_prob,\n",
    "                        strategy=\"cost\",  # \"cost\" | \"f1\" | \"balanced_accuracy\" | \"accuracy\"\n",
    "                        fp_cost=1.0, fn_cost=4.0,\n",
    "                        grid=None):\n",
    "    sw = sweep_thresholds(y_true, y_prob, grid)\n",
    "    if strategy == \"f1\":\n",
    "        idx = sw[\"f1\"].idxmax()\n",
    "    elif strategy == \"balanced_accuracy\":\n",
    "        idx = sw[\"bacc\"].idxmax()\n",
    "    elif strategy == \"accuracy\":\n",
    "        idx = sw[\"acc\"].idxmax()\n",
    "    elif strategy == \"cost\":\n",
    "        cost = sw[\"fp\"]*fp_cost + sw[\"fn\"]*fn_cost\n",
    "        sw[\"cost\"] = cost\n",
    "        idx = cost.idxmin()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown strategy\")\n",
    "    return float(sw.loc[idx, \"thr\"]), sw\n",
    "\n",
    "def evaluate_at_threshold(y_true, y_prob, thr):\n",
    "    \"\"\"Return both threshold-free and at-threshold metrics.\"\"\"\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    n = len(y_true)\n",
    "    return {\n",
    "        \"Threshold\": thr,\n",
    "        \"ROC_AUC\": roc_auc_score(y_true, y_prob),\n",
    "        \"PR_AUC\": average_precision_score(y_true, y_prob),\n",
    "        \"Accuracy\": (tn + tp) / n,\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"Balanced_Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"MCC\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"Brier\": brier_score_loss(y_true, y_prob),\n",
    "        \"LogLoss\": log_loss(y_true, y_prob),\n",
    "        \"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Base models (LogReg + RandomForest)\n",
    "# ============================================================\n",
    "def fit_logreg(X_train, y_train, random_state=42):\n",
    "    lr = LogisticRegression(\n",
    "        max_iter=1000, solver=\"liblinear\",\n",
    "        class_weight=\"balanced\", random_state=random_state\n",
    "    )\n",
    "    lr.fit(X_train, y_train)\n",
    "    return lr\n",
    "\n",
    "def fit_random_forest(X_train, y_train, random_state=42):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=600, max_depth=None, max_features=\"sqrt\",\n",
    "        min_samples_leaf=1, class_weight=None,   # set to \"balanced\" if desired\n",
    "        n_jobs=-1, random_state=random_state\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf\n",
    "\n",
    "# ============================================================\n",
    "# Train, weight, threshold, evaluate, pretty-print\n",
    "# (uses your X_* / y_* variables)\n",
    "# ============================================================\n",
    "# 1) Train\n",
    "lr = fit_logreg(X_train_res_scaled, y_train_res)\n",
    "rf = fit_random_forest(X_train_res_scaled, y_train_res)\n",
    "\n",
    "# 2) Probabilities\n",
    "val_lr   = lr.predict_proba(X_val_scaled)[:, 1]\n",
    "val_rf   = rf.predict_proba(X_val_scaled)[:, 1]\n",
    "test_lr  = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "test_rf  = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 3) Learn convex weights on validation\n",
    "P_val  = np.column_stack([val_lr, val_rf])   # (n_val, 2)\n",
    "P_test = np.column_stack([test_lr, test_rf]) # (n_test, 2)\n",
    "w_star = solve_simplex_brier(P_val, y_val, iters=1500, lr=0.5)\n",
    "print(\"Ensemble weights (LR, RF):\", np.round(w_star, 4), \"sum=\", round(w_star.sum(), 4))\n",
    "\n",
    "val_ens  = P_val.dot(w_star)\n",
    "test_ens = P_test.dot(w_star)\n",
    "\n",
    "# 4) Choose threshold on VALIDATION ENSEMBLE\n",
    "THRESH_STRATEGY = \"cost\"    # \"cost\" | \"f1\" | \"balanced_accuracy\" | \"accuracy\"\n",
    "FP_COST, FN_COST = 1.0, 4.0\n",
    "thr, sweep = find_best_threshold(y_val, val_ens,\n",
    "                                 strategy=THRESH_STRATEGY,\n",
    "                                 fp_cost=FP_COST, fn_cost=FN_COST)\n",
    "print(\"Chosen threshold (validation):\", round(thr, 3))\n",
    "\n",
    "# 5) Evaluate VAL + TEST at same threshold\n",
    "res_lr_val   = evaluate_at_threshold(y_val,  val_lr,   thr)\n",
    "res_rf_val   = evaluate_at_threshold(y_val,  val_rf,   thr)\n",
    "res_ens_val  = evaluate_at_threshold(y_val,  val_ens,  thr)\n",
    "res_lr_test  = evaluate_at_threshold(y_test, test_lr,  thr)\n",
    "res_rf_test  = evaluate_at_threshold(y_test, test_rf,  thr)\n",
    "res_ens_test = evaluate_at_threshold(y_test, test_ens, thr)\n",
    "\n",
    "summary_val = pd.DataFrame([\n",
    "    {\"Model\":\"LogisticReg\",      **res_lr_val},\n",
    "    {\"Model\":\"RandomForest\",     **res_rf_val},\n",
    "    {\"Model\":\"Ensemble(LR+RF)\",  **res_ens_val},\n",
    "])\n",
    "\n",
    "summary_test = pd.DataFrame([\n",
    "    {\"Model\":\"LogisticReg\",      **res_lr_test},\n",
    "    {\"Model\":\"RandomForest\",     **res_rf_test},\n",
    "    {\"Model\":\"Ensemble(LR+RF)\",  **res_ens_test},\n",
    "])\n",
    "\n",
    "# Add cost columns\n",
    "summary_val[\"ExpectedCost\"] = summary_val[\"FP\"]*FP_COST + summary_val[\"FN\"]*FN_COST\n",
    "summary_test[\"ExpectedCost\"] = summary_test[\"FP\"]*FP_COST + summary_test[\"FN\"]*FN_COST\n",
    "summary_val[\"CostPerCase\"]  = summary_val[\"ExpectedCost\"] / len(y_val)\n",
    "summary_test[\"CostPerCase\"] = summary_test[\"ExpectedCost\"] / len(y_test)\n",
    "\n",
    "# Select + order columns for display\n",
    "cols_show = [\n",
    "    \"Model\",\"Threshold\",\"ROC_AUC\",\"PR_AUC\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\n",
    "    \"Balanced_Accuracy\",\"MCC\",\"Brier\",\"LogLoss\",\"TN\",\"FP\",\"FN\",\"TP\",\"ExpectedCost\",\"CostPerCase\"\n",
    "]\n",
    "summary_val = summary_val[cols_show].round(4)\n",
    "summary_test = summary_test[cols_show].round(4)\n",
    "\n",
    "# 6) Pretty print (notebook Styler or console tabulate)\n",
    "print_or_display(summary_val, summary_test)\n",
    "\n",
    "# 7) (Optional) Export to CSV\n",
    "# summary_val.to_csv(\"validation_summary.csv\", index=False)\n",
    "# summary_test.to_csv(\"test_summary.csv\", index=False)\n",
    "# pd.DataFrame(sweep).to_csv(\"threshold_sweep_validation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628aeddc-8084-4bc3-af50-c795a40ad19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for LR share on val: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Sweep mix to see why LR dominates\n",
    "alphas = np.linspace(0, 1, 21)\n",
    "briers = [brier_score_loss(y_val, a*val_lr + (1-a)*val_rf) for a in alphas]\n",
    "best_a = alphas[np.argmin(briers)]\n",
    "print(\"Best alpha for LR share on val:\", round(best_a,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b404fcc-5e33-401f-b8af-efb13e4d34cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppanta/puru_proj/proj_v0/hints6_v0/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble simplex weights (sum=1):\n",
      "LogisticReg     0.6710\n",
      "HistGB          0.2191\n",
      "ExtraTrees      0.1099\n",
      "RandomForest    0.0000\n",
      "GradBoost       0.0000\n",
      "SVC             0.0000\n",
      "KNN             0.0000\n",
      "GaussianNB      0.0000\n",
      "XGBoost         0.0000\n",
      "dtype: float64\n",
      "Sum: 1.0\n",
      "\n",
      "Chosen threshold (validation): 0.34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>VALIDATION (threshold chosen here)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>ExpectedCost</th>\n",
       "      <th>CostPerCase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7665</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.2789</td>\n",
       "      <td>830</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>24</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7694</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.8654</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.2747</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>0.6005</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>817</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.3381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>804</td>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>24</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.3556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>817</td>\n",
       "      <td>65</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.3587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>0.5805</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.3114</td>\n",
       "      <td>801</td>\n",
       "      <td>81</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.3628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.6669</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.5529</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.3262</td>\n",
       "      <td>830</td>\n",
       "      <td>52</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.3659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7069</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.1775</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>819</td>\n",
       "      <td>63</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>367.0</td>\n",
       "      <td>0.3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGB</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7192</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>834</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.3782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.5081</td>\n",
       "      <td>646</td>\n",
       "      <td>236</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.4522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.6115</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>1.6445</td>\n",
       "      <td>439</td>\n",
       "      <td>443</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>543.0</td>\n",
       "      <td>0.5581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Threshold  ROC_AUC  PR_AUC  Accuracy  Precision  Recall  \\\n",
       "9      Ensemble       0.34   0.7665  0.2457    0.8777     0.3158  0.2637   \n",
       "0   LogisticReg       0.34   0.7694  0.2606    0.8654     0.2778  0.2747   \n",
       "3     GradBoost       0.34   0.7173  0.2082    0.8510     0.2353  0.2637   \n",
       "4    ExtraTrees       0.34   0.7134  0.1959    0.8602     0.2353  0.2198   \n",
       "1  RandomForest       0.34   0.7120  0.1994    0.8469     0.2212  0.2527   \n",
       "5           SVC       0.34   0.6669  0.1763    0.8684     0.2239  0.1648   \n",
       "8       XGBoost       0.34   0.7069  0.1816    0.8571     0.1923  0.1648   \n",
       "2        HistGB       0.34   0.7192  0.2012    0.8684     0.1864  0.1209   \n",
       "6           KNN       0.34   0.6850  0.1638    0.7050     0.1449  0.4396   \n",
       "7    GaussianNB       0.34   0.6707  0.2012    0.5190     0.1297  0.7253   \n",
       "\n",
       "       F1  Balanced_Accuracy     MCC   Brier  LogLoss   TN   FP  FN  TP  \\\n",
       "9  0.2874             0.6024  0.2222  0.0807   0.2789  830   52  67  24   \n",
       "0  0.2762             0.6005  0.2020  0.0821   0.2884  817   65  66  25   \n",
       "3  0.2487             0.5877  0.1666  0.0897   0.3090  804   78  67  24   \n",
       "4  0.2273             0.5730  0.1506  0.0879   0.3054  817   65  71  20   \n",
       "1  0.2359             0.5805  0.1516  0.0898   0.3114  801   81  68  23   \n",
       "5  0.1899             0.5529  0.1217  0.0921   0.3262  830   52  76  15   \n",
       "8  0.1775             0.5467  0.1002  0.0920   0.3291  819   63  76  15   \n",
       "2  0.1467             0.5332  0.0811  0.0908   0.3552  834   48  80  11   \n",
       "6  0.2180             0.5860  0.1111  0.1211   0.5081  646  236  51  40   \n",
       "7  0.2200             0.6115  0.1300  0.3397   1.6445  439  443  25  66   \n",
       "\n",
       "   ExpectedCost  CostPerCase  \n",
       "9         320.0       0.3289  \n",
       "0         329.0       0.3381  \n",
       "3         346.0       0.3556  \n",
       "4         349.0       0.3587  \n",
       "1         353.0       0.3628  \n",
       "5         356.0       0.3659  \n",
       "8         367.0       0.3772  \n",
       "2         368.0       0.3782  \n",
       "6         440.0       0.4522  \n",
       "7         543.0       0.5581  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='margin:10px 0;border-top:2px solid #888;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>TEST (evaluated at the same threshold)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>ExpectedCost</th>\n",
       "      <th>CostPerCase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>803</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.8828</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>0.3021</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>826</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>33</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.3556</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.2858</td>\n",
       "      <td>811</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.3124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.2485</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.6254</td>\n",
       "      <td>0.2484</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>820</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "      <td>307.0</td>\n",
       "      <td>0.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.2911</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>838</td>\n",
       "      <td>45</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0.3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGB</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7471</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.8828</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>840</td>\n",
       "      <td>43</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.3361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.5993</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>813</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.3392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5844</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.2864</td>\n",
       "      <td>826</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.3422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>0.2078</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>681</td>\n",
       "      <td>202</td>\n",
       "      <td>37</td>\n",
       "      <td>53</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.3597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>1.4876</td>\n",
       "      <td>474</td>\n",
       "      <td>409</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.5190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Threshold  ROC_AUC  PR_AUC  Accuracy  Precision  Recall  \\\n",
       "0   LogisticReg       0.34   0.8000  0.3149    0.8664     0.3333  0.4444   \n",
       "9      Ensemble       0.34   0.8072  0.3229    0.8828     0.3667  0.3667   \n",
       "1  RandomForest       0.34   0.7781  0.2726    0.8664     0.3077  0.3556   \n",
       "4    ExtraTrees       0.34   0.7640  0.2485    0.8726     0.3152  0.3222   \n",
       "5           SVC       0.34   0.7059  0.2241    0.8849     0.3382  0.2556   \n",
       "2        HistGB       0.34   0.7471  0.2737    0.8828     0.3065  0.2111   \n",
       "3     GradBoost       0.34   0.7647  0.2549    0.8613     0.2632  0.2778   \n",
       "8       XGBoost       0.34   0.7586  0.2823    0.8705     0.2692  0.2333   \n",
       "6           KNN       0.34   0.7502  0.2183    0.7544     0.2078  0.5889   \n",
       "7    GaussianNB       0.34   0.6978  0.2126    0.5550     0.1389  0.7333   \n",
       "\n",
       "       F1  Balanced_Accuracy     MCC   Brier  LogLoss   TN   FP  FN  TP  \\\n",
       "0  0.3810             0.6769  0.3118  0.0777   0.2701  803   80  50  40   \n",
       "9  0.3667             0.6511  0.3021  0.0745   0.2593  826   57  57  33   \n",
       "1  0.3299             0.6370  0.2570  0.0814   0.2858  811   72  58  32   \n",
       "4  0.3187             0.6254  0.2484  0.0813   0.2822  820   63  61  29   \n",
       "5  0.2911             0.6023  0.2325  0.0858   0.3030  838   45  67  23   \n",
       "2  0.2500             0.5812  0.1926  0.0825   0.3253  840   43  71  19   \n",
       "3  0.2703             0.5993  0.1938  0.0821   0.2845  813   70  65  25   \n",
       "8  0.2500             0.5844  0.1801  0.0810   0.2864  826   57  69  21   \n",
       "6  0.3072             0.6801  0.2373  0.1079   0.4411  681  202  37  53   \n",
       "7  0.2336             0.6351  0.1566  0.3104   1.4876  474  409  24  66   \n",
       "\n",
       "   ExpectedCost  CostPerCase  \n",
       "0         280.0       0.2878  \n",
       "9         285.0       0.2929  \n",
       "1         304.0       0.3124  \n",
       "4         307.0       0.3155  \n",
       "5         313.0       0.3217  \n",
       "2         327.0       0.3361  \n",
       "3         330.0       0.3392  \n",
       "8         333.0       0.3422  \n",
       "6         350.0       0.3597  \n",
       "7         505.0       0.5190  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_score, recall_score,\n",
    "    f1_score, balanced_accuracy_score, matthews_corrcoef, brier_score_loss,\n",
    "    log_loss, confusion_matrix\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Pretty table helpers\n",
    "# ============================================================\n",
    "def _is_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        return \"IPKernelApp\" in get_ipython().config\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def style_summary(df: pd.DataFrame, caption: str = \"\"):\n",
    "    higher_better = [\n",
    "        \"ROC_AUC\",\"PR_AUC\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\n",
    "        \"Balanced_Accuracy\",\"MCC\"\n",
    "    ]\n",
    "    lower_better = [\"Brier\",\"LogLoss\",\"ExpectedCost\",\"CostPerCase\",\"FP\",\"FN\"]\n",
    "    fmt = {col: \"{:.4f}\" for col in df.columns if df[col].dtype.kind in \"fc\"}\n",
    "    for c in [\"TN\",\"FP\",\"FN\",\"TP\"]:\n",
    "        if c in df.columns: fmt[c] = \"{:.0f}\"\n",
    "    s = (df.style\n",
    "         .set_caption(caption)\n",
    "         .format(fmt)\n",
    "         .set_properties(**{\"text-align\":\"center\"})\n",
    "         .set_table_styles([\n",
    "             {\"selector\":\"caption\",\"props\":[(\"caption-side\",\"top\"),(\"font-weight\",\"bold\"),(\"font-size\",\"110%\")]},\n",
    "             {\"selector\":\"th\",\"props\":[(\"text-align\",\"center\"),(\"font-weight\",\"bold\")]},\n",
    "             {\"selector\":\"td\",\"props\":[(\"padding\",\"6px 10px\")]}\n",
    "         ]))\n",
    "    for col in higher_better:\n",
    "        if col in df.columns: s = s.highlight_max(subset=[col], color=\"#d2f5d2\")\n",
    "    for col in lower_better:\n",
    "        if col in df.columns: s = s.highlight_min(subset=[col], color=\"#d2f5d2\")\n",
    "    return s\n",
    "\n",
    "def print_or_display(df_val: pd.DataFrame, df_tst: pd.DataFrame):\n",
    "    \"\"\"Notebook-safe display without using .style or jinja2.\"\"\"\n",
    "    if _is_notebook():\n",
    "        from IPython.display import display, HTML\n",
    "        display(HTML(\"<h4>VALIDATION (threshold chosen here)</h4>\"))\n",
    "        display(df_val)\n",
    "        display(HTML(\"<div style='margin:10px 0;border-top:2px solid #888;'></div>\"))\n",
    "        display(HTML(\"<h4>TEST (evaluated at the same threshold)</h4>\"))\n",
    "        display(df_tst)\n",
    "    else:\n",
    "        try:\n",
    "            from tabulate import tabulate\n",
    "            print(\"\\nVALIDATION (threshold chosen here)\")\n",
    "            print(tabulate(df_val, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "            print(\"\\nTEST (evaluated at the same threshold)\")\n",
    "            print(tabulate(df_tst, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "        except Exception:\n",
    "            print(\"\\nVALIDATION (threshold chosen here)\")\n",
    "            print(df_val.to_string(index=False))\n",
    "            print(\"\\nTEST (evaluated at the same threshold)\")\n",
    "            print(df_tst.to_string(index=False))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Core helpers (simplex weighting + metrics)\n",
    "# ============================================================\n",
    "def proj_simplex(v):\n",
    "    \"\"\"Project vector v onto {w >= 0, sum(w)=1}.\"\"\"\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "    rho = np.nonzero(u * np.arange(1, len(u)+1) > (cssv - 1))[0][-1]\n",
    "    theta = (cssv[rho] - 1) / (rho + 1.0)\n",
    "    return np.maximum(v - theta, 0.0)\n",
    "\n",
    "def solve_simplex_brier(P, y, iters=1500, lr=0.5, seed=42):\n",
    "    \"\"\"\n",
    "    Learn convex weights that minimize Brier score on validation.\n",
    "    P: (n_val, k) matrix of validation probabilities (columns = models)\n",
    "    y: (n_val,) labels {0,1}\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    k = P.shape[1]\n",
    "    w = np.ones(k) / k\n",
    "    for _ in range(iters):\n",
    "        grad = (2.0 / len(y)) * P.T.dot(P.dot(w) - y)\n",
    "        w = proj_simplex(w - lr * grad)\n",
    "    return w\n",
    "\n",
    "def sweep_thresholds(y_true, y_prob, grid=None):\n",
    "    if grid is None: grid = np.linspace(0, 1, 101)\n",
    "    rows = []\n",
    "    for t in grid:\n",
    "        y_pred = (y_prob >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        n = len(y_true)\n",
    "        rows.append({\n",
    "            \"thr\": t,\n",
    "            \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "            \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "            \"acc\": (tn+tp)/n,\n",
    "            \"bacc\": balanced_accuracy_score(y_true, y_pred),\n",
    "            \"fp\": fp, \"fn\": fn\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def find_best_threshold(y_true, y_prob,\n",
    "                        strategy=\"cost\",  # \"cost\" | \"f1\" | \"balanced_accuracy\" | \"accuracy\"\n",
    "                        fp_cost=1.0, fn_cost=4.0,\n",
    "                        grid=None):\n",
    "    sw = sweep_thresholds(y_true, y_prob, grid)\n",
    "    if strategy == \"f1\":\n",
    "        idx = sw[\"f1\"].idxmax()\n",
    "    elif strategy == \"balanced_accuracy\":\n",
    "        idx = sw[\"bacc\"].idxmax()\n",
    "    elif strategy == \"accuracy\":\n",
    "        idx = sw[\"acc\"].idxmax()\n",
    "    elif strategy == \"cost\":\n",
    "        sw[\"cost\"] = sw[\"fp\"]*fp_cost + sw[\"fn\"]*fn_cost\n",
    "        idx = sw[\"cost\"].idxmin()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown strategy\")\n",
    "    return float(sw.loc[idx, \"thr\"]), sw\n",
    "\n",
    "def evaluate_at_threshold(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    n = len(y_true)\n",
    "    return {\n",
    "        \"Threshold\": thr,\n",
    "        \"ROC_AUC\": roc_auc_score(y_true, y_prob),\n",
    "        \"PR_AUC\": average_precision_score(y_true, y_prob),\n",
    "        \"Accuracy\": (tn + tp) / n,\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"Balanced_Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"MCC\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"Brier\": brier_score_loss(y_true, y_prob),\n",
    "        \"LogLoss\": log_loss(y_true, y_prob),\n",
    "        \"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Model zoo — adjust as you like\n",
    "# (All trained on scaled features you already have.)\n",
    "# ============================================================\n",
    "def get_model_zoo(random_state=42):\n",
    "    models = {\n",
    "        \"LogisticReg\": LogisticRegression(\n",
    "            max_iter=1000, solver=\"liblinear\", class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=600, max_depth=None, max_features=\"sqrt\",\n",
    "            min_samples_leaf=1, class_weight=None, n_jobs=-1,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"HistGB\": HistGradientBoostingClassifier(\n",
    "            learning_rate=0.05, max_iter=400, max_depth=None,\n",
    "            l2_regularization=0.0, random_state=random_state\n",
    "        ),\n",
    "        \"GradBoost\": GradientBoostingClassifier(\n",
    "            n_estimators=400, learning_rate=0.05, max_depth=3, random_state=random_state\n",
    "        ),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(\n",
    "            n_estimators=600, max_depth=None, max_features=\"sqrt\",\n",
    "            min_samples_leaf=1, n_jobs=-1, random_state=random_state\n",
    "        ),\n",
    "        \"SVC\": SVC(\n",
    "            kernel=\"rbf\", C=1.0, gamma=\"scale\", probability=True,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"KNN\": KNeighborsClassifier(\n",
    "            n_neighbors=25, weights=\"distance\", p=2\n",
    "        ),\n",
    "        \"GaussianNB\": GaussianNB()\n",
    "    }\n",
    "    # Optional: XGBoost (if installed)\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "        models[\"XGBoost\"] = XGBClassifier(\n",
    "            n_estimators=700, learning_rate=0.05, max_depth=4,\n",
    "            subsample=0.8, colsample_bytree=0.8, min_child_weight=1,\n",
    "            reg_lambda=1.0, tree_method=\"hist\",\n",
    "            eval_metric=\"logloss\", n_jobs=-1, random_state=random_state\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    return models\n",
    "\n",
    "# ============================================================\n",
    "# === MAIN: Train, get probs, learn weights, threshold, evaluate\n",
    "# ============================================================\n",
    "# 0) Config\n",
    "THRESH_STRATEGY = \"cost\"    # \"cost\" | \"f1\" | \"balanced_accuracy\" | \"accuracy\"\n",
    "FP_COST, FN_COST = 1.0, 4.0\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 1) Build models\n",
    "models = get_model_zoo(RANDOM_STATE)\n",
    "\n",
    "# 2) Fit on TRAIN, collect validation & test probabilities\n",
    "val_probs = {}\n",
    "test_probs = {}\n",
    "\n",
    "for name, mdl in models.items():\n",
    "    mdl.fit(X_train_res_scaled, y_train_res)\n",
    "    val_probs[name]  = mdl.predict_proba(X_val_scaled)[:, 1]\n",
    "    test_probs[name] = mdl.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 3) Stack probs into matrices with fixed column order\n",
    "model_order = list(val_probs.keys())   # keep insertion order\n",
    "P_val  = np.column_stack([val_probs[m]  for m in model_order])\n",
    "P_test = np.column_stack([test_probs[m] for m in model_order])\n",
    "\n",
    "# 4) Learn convex (simplex) weights on VALIDATION (Brier-optimal)\n",
    "w_star = solve_simplex_brier(P_val, y_val, iters=1500, lr=0.5)\n",
    "weights = pd.Series(w_star, index=model_order).sort_values(ascending=False)\n",
    "print(\"\\nEnsemble simplex weights (sum=1):\")\n",
    "print(weights.round(4))\n",
    "print(\"Sum:\", round(weights.sum(), 6))\n",
    "\n",
    "# Ensemble probabilities\n",
    "val_ens  = P_val.dot(w_star)\n",
    "test_ens = P_test.dot(w_star)\n",
    "\n",
    "# 5) Choose threshold on VALIDATION ENSEMBLE\n",
    "thr, sweep = find_best_threshold(y_val, val_ens,\n",
    "                                 strategy=THRESH_STRATEGY,\n",
    "                                 fp_cost=FP_COST, fn_cost=FN_COST)\n",
    "print(\"\\nChosen threshold (validation):\", round(thr, 3))\n",
    "\n",
    "# 6) Evaluate VAL + TEST for each model and for the ENSEMBLE (same threshold)\n",
    "rows_val, rows_test = [], []\n",
    "\n",
    "# Individual models\n",
    "for name in model_order:\n",
    "    rows_val.append({\"Model\": name, **evaluate_at_threshold(y_val,  val_probs[name],  thr)})\n",
    "    rows_test.append({\"Model\": name, **evaluate_at_threshold(y_test, test_probs[name], thr)})\n",
    "\n",
    "# Ensemble row\n",
    "rows_val.append({\"Model\": \"Ensemble\", **evaluate_at_threshold(y_val,  val_ens,  thr)})\n",
    "rows_test.append({\"Model\": \"Ensemble\", **evaluate_at_threshold(y_test, test_ens, thr)})\n",
    "\n",
    "summary_val  = pd.DataFrame(rows_val)\n",
    "summary_test = pd.DataFrame(rows_test)\n",
    "\n",
    "# 7) Add cost columns and arrange\n",
    "summary_val[\"ExpectedCost\"] = summary_val[\"FP\"]*FP_COST + summary_val[\"FN\"]*FN_COST\n",
    "summary_test[\"ExpectedCost\"] = summary_test[\"FP\"]*FP_COST + summary_test[\"FN\"]*FN_COST\n",
    "summary_val[\"CostPerCase\"]  = summary_val[\"ExpectedCost\"] / len(y_val)\n",
    "summary_test[\"CostPerCase\"] = summary_test[\"ExpectedCost\"] / len(y_test)\n",
    "\n",
    "cols_show = [\n",
    "    \"Model\",\"Threshold\",\"ROC_AUC\",\"PR_AUC\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\n",
    "    \"Balanced_Accuracy\",\"MCC\",\"Brier\",\"LogLoss\",\"TN\",\"FP\",\"FN\",\"TP\",\"ExpectedCost\",\"CostPerCase\"\n",
    "]\n",
    "summary_val  = summary_val[cols_show].round(4).sort_values([\"ExpectedCost\",\"CostPerCase\",\"PR_AUC\"], ascending=[True,True,False])\n",
    "summary_test = summary_test[cols_show].round(4).sort_values([\"ExpectedCost\",\"CostPerCase\",\"PR_AUC\"], ascending=[True,True,False])\n",
    "\n",
    "# 8) Pretty display\n",
    "print_or_display(summary_val, summary_test)\n",
    "\n",
    "# 9) (Optional) CSV exports\n",
    "# summary_val.to_csv(\"validation_summary_all_models.csv\", index=False)\n",
    "# summary_test.to_csv(\"test_summary_all_models.csv\", index=False)\n",
    "# pd.DataFrame({\"model\":model_order, \"weight\":w_star}).to_csv(\"ensemble_weights.csv\", index=False)\n",
    "# pd.DataFrame(sweep).to_csv(\"threshold_sweep_validation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d396c3-3a95-469f-9fd4-eaf26895cf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppanta/puru_proj/proj_v0/hints6_v0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ======================\n",
    "# Try to import SHAP (optional)\n",
    "# ======================\n",
    "USE_SHAP = True\n",
    "try:\n",
    "    import shap  # pip install shap  OR  conda install -c conda-forge shap\n",
    "except Exception:\n",
    "    USE_SHAP = False\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# ======================\n",
    "# 0) DataFrames for names\n",
    "# ======================\n",
    "X_train_df = pd.DataFrame(X_train_res_scaled, columns=features)\n",
    "X_val_df   = pd.DataFrame(X_val_scaled,       columns=features)\n",
    "X_test_df  = pd.DataFrame(X_test_scaled,      columns=features)\n",
    "\n",
    "# Choose which split to explain (commonly validation)\n",
    "X_explain = X_val_df\n",
    "y_explain = y_val\n",
    "\n",
    "# Background sample for SHAP (small subset of train for speed)\n",
    "bg_n = min(256, len(X_train_df))\n",
    "background = X_train_df.sample(bg_n, random_state=42)\n",
    "\n",
    "# ======================\n",
    "# 1) Model zoo & training (skip if you already have `models`)\n",
    "# ======================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def get_model_zoo(random_state=42):\n",
    "    zoo = {\n",
    "        \"LogisticReg\": LogisticRegression(\n",
    "            max_iter=1000, solver=\"liblinear\", class_weight=\"balanced\", random_state=random_state\n",
    "        ),\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=600, max_depth=None, max_features=\"sqrt\",\n",
    "            min_samples_leaf=1, class_weight=None, n_jobs=-1, random_state=random_state\n",
    "        ),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(\n",
    "            n_estimators=600, max_depth=None, max_features=\"sqrt\",\n",
    "            min_samples_leaf=1, n_jobs=-1, random_state=random_state\n",
    "        ),\n",
    "        \"GradBoost\": GradientBoostingClassifier(\n",
    "            n_estimators=400, learning_rate=0.05, max_depth=3, random_state=random_state\n",
    "        ),\n",
    "        \"HistGB\": HistGradientBoostingClassifier(\n",
    "            learning_rate=0.05, max_iter=400, random_state=random_state\n",
    "        ),\n",
    "        \"SVC\": SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", probability=True, random_state=random_state),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=25, weights=\"distance\"),\n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "    }\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "        zoo[\"XGBoost\"] = XGBClassifier(\n",
    "            n_estimators=700, learning_rate=0.05, max_depth=4,\n",
    "            subsample=0.8, colsample_bytree=0.8, min_child_weight=1,\n",
    "            reg_lambda=1.0, tree_method=\"hist\", eval_metric=\"logloss\",\n",
    "            n_jobs=-1, random_state=random_state\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    return zoo\n",
    "\n",
    "# Train models (comment this block if you already have `models`)\n",
    "models = get_model_zoo(42)\n",
    "for name, mdl in models.items():\n",
    "    mdl.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "# ======================\n",
    "# 2) Explainers / importance (SHAP with new API; permutation fallback)\n",
    "# ======================\n",
    "def make_explainer(model, model_name, background_df):\n",
    "    \"\"\"\n",
    "    Robust SHAP explainer factory compatible with newer/older SHAP.\n",
    "    Uses maskers for new API; falls back gracefully as needed.\n",
    "    \"\"\"\n",
    "    import shap\n",
    "    name = str(model_name).lower()\n",
    "\n",
    "    # Build masker (new SHAP API)\n",
    "    try:\n",
    "        masker = shap.maskers.Independent(background_df)\n",
    "    except Exception:\n",
    "        masker = background_df\n",
    "\n",
    "    # Tree-based → TreeExplainer\n",
    "    if any(tok in name for tok in [\"randomforest\", \"extratrees\", \"gradboost\", \"histgb\", \"xgboost\", \"xgb\"]):\n",
    "        return shap.TreeExplainer(model)\n",
    "\n",
    "    # Linear models → LinearExplainer\n",
    "    if \"logistic\" in name or \"linear\" in name:\n",
    "        try:\n",
    "            return shap.LinearExplainer(model, masker)\n",
    "        except TypeError:\n",
    "            return shap.LinearExplainer(model, background_df)\n",
    "\n",
    "    # Generic fallback\n",
    "    try:\n",
    "        return shap.Explainer(model, masker)\n",
    "    except TypeError:\n",
    "        # very old fallback\n",
    "        return shap.KernelExplainer(model.predict_proba, background_df)\n",
    "\n",
    "def compute_shap_importance(model, model_name, X_bg, X_data, top_k=None):\n",
    "    \"\"\"\n",
    "    Returns (importance_df, shap_values_matrix_for_class1).\n",
    "    importance_df has columns: Feature, <model>_MeanAbsSHAP, <model>_Rank\n",
    "    \"\"\"\n",
    "    explainer = make_explainer(model, model_name, X_bg)\n",
    "    shap_out = explainer(X_data)  # shap.Explanation (new) or array/list (old)\n",
    "\n",
    "    # Normalize to (n_samples, n_features) for positive class\n",
    "    if hasattr(shap_out, \"values\"):  # Explanation\n",
    "        values = shap_out.values\n",
    "    else:\n",
    "        values = shap_out\n",
    "\n",
    "    # Handle multi-class outputs (n, n_features, n_classes)\n",
    "    if isinstance(values, np.ndarray) and values.ndim == 3 and values.shape[-1] >= 2:\n",
    "        values = values[..., 1]\n",
    "    if isinstance(values, list) and len(values) >= 2 and isinstance(values[1], np.ndarray):\n",
    "        values = values[1]\n",
    "\n",
    "    mean_abs = np.abs(values).mean(axis=0)\n",
    "    col_mean = f\"{model_name}_MeanAbsSHAP\"\n",
    "    col_rank = f\"{model_name}_Rank\"\n",
    "    imp_df = (pd.DataFrame({\"Feature\": X_data.columns, col_mean: mean_abs})\n",
    "                .sort_values(col_mean, ascending=False))\n",
    "    if top_k:\n",
    "        imp_df = imp_df.head(top_k).copy()\n",
    "    imp_df[col_rank] = np.arange(1, len(imp_df) + 1)\n",
    "    return imp_df, values\n",
    "\n",
    "def compute_perm_importance(model, model_name, X_ref, y_ref, n_repeats=10, random_state=42, top_k=None):\n",
    "    \"\"\"\n",
    "    Model-agnostic permutation importance (mean abs decrease in proba MSE proxy).\n",
    "    Returns (importance_df, None). Uses scoring on predicted proba for class 1.\n",
    "    \"\"\"\n",
    "    # Use validation split for permutation importance\n",
    "    r = permutation_importance(\n",
    "        model, X_ref, y_ref,\n",
    "        scoring=\"neg_brier_score\",  # aligns with probability quality\n",
    "        n_repeats=n_repeats, random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "    # r.importances_mean can be negative due to noise; use abs to rank magnitude\n",
    "    scores = np.abs(r.importances_mean)\n",
    "    col_mean = f\"{model_name}_PermImportance\"\n",
    "    col_rank = f\"{model_name}_Rank\"\n",
    "    imp_df = (pd.DataFrame({\"Feature\": X_ref.columns, col_mean: scores})\n",
    "                .sort_values(col_mean, ascending=False))\n",
    "    if top_k:\n",
    "        imp_df = imp_df.head(top_k).copy()\n",
    "    imp_df[col_rank] = np.arange(1, len(imp_df) + 1)\n",
    "    return imp_df, None\n",
    "\n",
    "# ======================\n",
    "# 3) Run for all models\n",
    "# ======================\n",
    "model_names = list(models.keys())\n",
    "per_model_tables = {}\n",
    "raw_values = {}  # SHAP arrays if SHAP used\n",
    "\n",
    "for name in model_names:\n",
    "    if USE_SHAP:\n",
    "        imp_df, shap_vals = compute_shap_importance(models[name], name, background, X_explain, top_k=None)\n",
    "        per_model_tables[name] = imp_df.reset_index(drop=True)\n",
    "        raw_values[name] = shap_vals  # (n_samples, n_features)\n",
    "    else:\n",
    "        imp_df, _ = compute_perm_importance(models[name], name, X_explain, y_explain, n_repeats=10)\n",
    "        per_model_tables[name] = imp_df.reset_index(drop=True)\n",
    "        raw_values[name] = None\n",
    "\n",
    "# ======================\n",
    "# 4) Build consensus tables\n",
    "# ======================\n",
    "consensus = pd.DataFrame({\"Feature\": features})\n",
    "\n",
    "# Merge each model’s (MeanAbsSHAP or PermImportance) and Rank\n",
    "for name, imp_df in per_model_tables.items():\n",
    "    val_col = f\"{name}_MeanAbsSHAP\" if USE_SHAP else f\"{name}_PermImportance\"\n",
    "    consensus = consensus.merge(imp_df[[\"Feature\", val_col, f\"{name}_Rank\"]], on=\"Feature\", how=\"left\")\n",
    "\n",
    "# Fill missing (if top_k used; here we used all)\n",
    "fill_vals = {}\n",
    "for name in model_names:\n",
    "    fill_vals[f\"{name}_Rank\"] = np.nan\n",
    "    fill_vals[f\"{name}_MeanAbsSHAP\" if USE_SHAP else f\"{name}_PermImportance\"] = 0.0\n",
    "consensus = consensus.fillna(fill_vals)\n",
    "\n",
    "# Average Rank (smaller = better). Penalize missing ranks by using len+1.\n",
    "adj_ranks = []\n",
    "for name in model_names:\n",
    "    r = consensus[f\"{name}_Rank\"].copy()\n",
    "    r = r.fillna(len(consensus) + 1)\n",
    "    adj_ranks.append(r)\n",
    "consensus[\"Avg_Rank\"] = np.mean(np.vstack(adj_ranks), axis=0)\n",
    "\n",
    "# Normalized importance per model to [0,1], then average\n",
    "norm_cols = []\n",
    "for name in model_names:\n",
    "    base_col = f\"{name}_MeanAbsSHAP\" if USE_SHAP else f\"{name}_PermImportance\"\n",
    "    maxv = consensus[base_col].max()\n",
    "    ncol = f\"{name}_NormImp\"\n",
    "    consensus[ncol] = consensus[base_col] / maxv if maxv > 0 else 0.0\n",
    "    norm_cols.append(ncol)\n",
    "\n",
    "consensus[\"Avg_NormImportance\"] = consensus[norm_cols].mean(axis=1)\n",
    "\n",
    "# Two sorted views\n",
    "consensus_by_rank = consensus.sort_values(\"Avg_Rank\").reset_index(drop=True)\n",
    "consensus_by_norm = consensus.sort_values(\"Avg_NormImportance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop 30 by Average Rank across models:\")\n",
    "print(consensus_by_rank[[\"Feature\",\"Avg_Rank\"] + [f\"{name}_Rank\" for name in model_names]].head(30))\n",
    "\n",
    "print(\"\\nTop 30 by Average Normalized Importance across models:\")\n",
    "print(consensus_by_norm[[\"Feature\",\"Avg_NormImportance\"] + norm_cols].head(30))\n",
    "\n",
    "# ======================\n",
    "# 5) (Optional) Save CSVs\n",
    "# ======================\n",
    "# for name, df_imp in per_model_tables.items():\n",
    "#     df_imp.to_csv(f\"importance_{name}.csv\", index=False)\n",
    "# consensus_by_rank.to_csv(\"consensus_by_rank.csv\", index=False)\n",
    "# consensus_by_norm.to_csv(\"consensus_by_avg_norm.csv\", index=False)\n",
    "\n",
    "# ======================\n",
    "# 6) (Optional) Quick SHAP plots if SHAP is available\n",
    "# ======================\n",
    "# if USE_SHAP:\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     # Example: beeswarm plot for a tree model (RandomForest) and for LR\n",
    "#     if raw_values.get(\"RandomForest\") is not None:\n",
    "#         shap.summary_plot(raw_values[\"RandomForest\"], X_explain, show=True)\n",
    "#     if raw_values.get(\"LogisticReg\") is not None:\n",
    "#         shap.summary_plot(raw_values[\"LogisticReg\"], X_explain, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f888e-2413-4bd8-97a3-4d91bca07d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (hints6_v0)",
   "language": "python",
   "name": "hints6_v0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
