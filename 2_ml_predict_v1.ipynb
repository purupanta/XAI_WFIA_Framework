{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58533de-1b35-4321-81ff-d250a3752c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import base_configs, deps, tr_va_te_split\n",
    "from utils import tr_va_te_split\n",
    "from utils.helpers import dir_helpers, rw_csv_helpers, feature_distr_helpers, feature_transform_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06f03b1-e12d-44b3-a23d-48a01912077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, math\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05238c2f-47e8-4d33-b6f4-ec343b0936ef",
   "metadata": {},
   "source": [
    "### 0 Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28a230e-5761-4726-81bb-05d4d324599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/ppanta/puru_proj/proj_v0/hints6_v0/op/hints6_public_filtered_v1_cleaned_encoded.csv\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Shape: (4865, 27)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "All columns: ['FreqGoProvider', 'Deaf', 'MedConditions_Diabetes', 'MedConditions_HighBP', 'MedConditions_HeartCondition', 'MedConditions_LungDisease', 'MedConditions_Depression', 'AverageSleepNight', 'AverageTimeSitting', 'EverHadCancer', 'Age', 'BirthGender', 'BMI', 'PHQ4', 'WeeklyMinutesModerateExercise', 'AvgDrinksPerWeek', 'GeneralHealth_Excellent', 'GeneralHealth_VeryGood', 'GeneralHealth_Good', 'GeneralHealth_Fair', 'GeneralHealth_Poor', 'smokeStat_Current', 'smokeStat_Former', 'smokeStat_Never', 'eCigUse_Current', 'eCigUse_Former', 'eCigUse_Never']\n"
     ]
    }
   ],
   "source": [
    "df_orig = rw_csv_helpers.read_csv_file(\"op/hints6_public_filtered_v1_cleaned_encoded.csv\", verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6719b3e-babe-4a16-8a3d-3a4e8c871e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for column 'MedConditions_HeartCondition' (only 0 and 1):\n",
      "MedConditions_HeartCondition\n",
      "0    4412\n",
      "1     453\n",
      "Name: count, dtype: int64\n",
      "Total (0/1 only): 4865\n"
     ]
    }
   ],
   "source": [
    "counts = feature_distr_helpers.count01(df_orig.copy(), \"MedConditions_HeartCondition\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032186b-7d2f-4272-9bf4-b6dc86e6230c",
   "metadata": {},
   "source": [
    "### 1 Train - Validation - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f71dcb8-7c8b-4fab-9dea-568a58d29460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig.copy()\n",
    "target_col = \"MedConditions_HeartCondition\"\n",
    "\n",
    "X = df_orig.drop(columns=[target_col])\n",
    "y = df_orig[target_col]\n",
    "\n",
    "result = tr_va_te_split.data_preprocessing(\n",
    "    verbose=0,       # 0, 1, or 2\n",
    "    X=X, y=y,\n",
    "    balance_method=\"adasyn\",  # or 'smote', 'smoteenn', 'none'\n",
    "    balance_kwargs={\"n_neighbors\": 5}  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df2753-ab0c-44a9-bb42-9ad6cd98dd6b",
   "metadata": {},
   "source": [
    "### 2 Train - Validation - Test value assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc80352-7ab5-4a1d-84c1-47bfaf32f678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:            X = (2919, 26),      y = (2919,)\n",
      "X_train_res shape:        X = (5271, 26),  y = (5271,)\n",
      "X_val shape:              X = (973, 26),        y = (973,)\n",
      "X_test shape:             X = (973, 26),       y = (973,)\n",
      "X_train_res_scaled shape: X = (5271, 26)\n",
      "X_val_scaled shape:       X = (973, 26)\n",
      "X_test_scaled shape:      X = (973, 26)\n",
      "features length:          n = 26\n"
     ]
    }
   ],
   "source": [
    "print_result = feature_distr_helpers.print_shapes_and_features(result, verbose = 1)\n",
    "\n",
    "# Value assignments for further calculations\n",
    "X_train_res_scaled = result['X_train_res_scaled']\n",
    "X_val_scaled       = result['X_val_scaled']\n",
    "X_test_scaled      = result['X_test_scaled']\n",
    "\n",
    "X_train     = result['X_train']\n",
    "X_train_res = result['X_train_res']\n",
    "X_val       = result['X_val']\n",
    "X_test      = result['X_test']\n",
    "\n",
    "y_train     = result['y_train']\n",
    "y_train_res = result['y_train_res']\n",
    "y_val       = result['y_val']\n",
    "y_test      = result['y_test']\n",
    "\n",
    "features    = result['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f888e-2413-4bd8-97a3-4d91bca07d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d3a3ed-d268-4e98-8ef7-fafb06135f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance (weights source):\n",
      "     roc_auc  pr_auc     ece\n",
      "lr    0.7691  0.2594  0.0471\n",
      "rf    0.7156  0.1941  0.0638\n",
      "xgb   0.7012  0.1782  0.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 599/600 [01:28<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-model mean(|SHAP|) (unnormalized) — head:\n",
      "                                 lr        rf       xgb\n",
      "feature                                                \n",
      "FreqGoProvider             0.172977  0.014643  0.255532\n",
      "Deaf                       0.041109  0.002282  0.055716\n",
      "MedConditions_Diabetes     0.149365  0.006012  0.074218\n",
      "MedConditions_HighBP       0.258893  0.013687  0.313645\n",
      "MedConditions_LungDisease  0.002699  0.004575  0.068493\n",
      "MedConditions_Depression   0.070492  0.014259  0.112413\n",
      "AverageSleepNight          0.069883  0.014701  0.159286\n",
      "AverageTimeSitting         0.122603  0.010116  0.302672\n",
      "EverHadCancer              0.112702  0.006342  0.180847\n",
      "Age                        0.859877  0.067954  0.967464\n",
      "\n",
      "Model weights used (normalized, aligned to columns):\n",
      "lr     0.3518\n",
      "rf     0.3274\n",
      "xgb    0.3208\n",
      "dtype: float64\n",
      "\n",
      "Top features by CompositeImportance:\n",
      "                                    lr       rf      xgb  CompositeImportance\n",
      "smokeStat_Never                0.17248  0.19645  0.15796              0.17567\n",
      "GeneralHealth_Good             0.15036  0.15122  0.14457              0.14878\n",
      "GeneralHealth_VeryGood         0.13482  0.14981  0.13287              0.13910\n",
      "smokeStat_Former               0.10689  0.07891  0.08555              0.09088\n",
      "Age                            0.04096  0.08867  0.07349              0.06701\n",
      "GeneralHealth_Fair             0.07114  0.03983  0.05230              0.05485\n",
      "smokeStat_Current              0.06675  0.03810  0.03752              0.04800\n",
      "GeneralHealth_Excellent        0.04752  0.04359  0.04661              0.04594\n",
      "eCigUse_Never                  0.07457  0.01040  0.02778              0.03855\n",
      "eCigUse_Former                 0.04448  0.01941  0.02188              0.02902\n",
      "MedConditions_HighBP           0.01233  0.01786  0.02382              0.01783\n",
      "FreqGoProvider                 0.00824  0.01911  0.01941              0.01538\n",
      "WeeklyMinutesModerateExercise  0.00052  0.02165  0.02528              0.01538\n",
      "BMI                            0.00661  0.01501  0.02475              0.01518\n",
      "AverageTimeSitting             0.00584  0.01320  0.02299              0.01375\n",
      "AverageSleepNight              0.00333  0.01918  0.01210              0.01133\n",
      "PHQ4                           0.00411  0.00817  0.02081              0.01080\n",
      "MedConditions_Depression       0.00336  0.01861  0.00854              0.01001\n",
      "AvgDrinksPerWeek               0.00373  0.00821  0.01560              0.00901\n",
      "EverHadCancer                  0.00537  0.00828  0.01374              0.00900\n",
      "\n",
      "Test-set metrics:\n",
      "     roc_auc  pr_auc     ece\n",
      "lr    0.8002  0.3152  0.0496\n",
      "rf    0.7761  0.2659  0.0620\n",
      "xgb   0.7572  0.2807  0.0557\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Multi-model SHAP + Composite Importance using YOUR splits\n",
    "# (uses: X_train_res_scaled, X_val_scaled, X_test_scaled,\n",
    "#        X_train, X_train_res, X_val, X_test,\n",
    "#        y_train, y_train_res, y_val, y_test, features)\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost (optional)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "import shap\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 0) Coercion helpers\n",
    "# -----------------------------------------------------------\n",
    "def to_df(X, columns):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return X.copy()\n",
    "    X = np.asarray(X)\n",
    "    if columns is None:\n",
    "        columns = [f\"f{i}\" for i in range(X.shape[1])]\n",
    "    return pd.DataFrame(X, columns=columns)\n",
    "\n",
    "def to_series(y, name=\"target\"):\n",
    "    if isinstance(y, pd.Series):\n",
    "        return y.copy()\n",
    "    return pd.Series(np.asarray(y).ravel(), name=name)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1) Metrics\n",
    "# -----------------------------------------------------------\n",
    "def expected_calibration_error(y_true, y_prob, n_bins=15):\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    inds = np.digitize(y_prob, bins) - 1\n",
    "    ece = 0.0\n",
    "    N = len(y_true)\n",
    "    for b in range(n_bins):\n",
    "        mask = inds == b\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        conf = y_prob[mask].mean()\n",
    "        acc = y_true[mask].mean()\n",
    "        ece += (mask.sum() / N) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def perf_summary(y_true, y_prob):\n",
    "    return {\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_prob),\n",
    "        \"pr_auc\": average_precision_score(y_true, y_prob),\n",
    "        \"ece\": expected_calibration_error(y_true, y_prob, n_bins=15)\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2) SHAP utilities (API-safe)\n",
    "# -----------------------------------------------------------\n",
    "def mean_abs_shap(shap_values, feature_names):\n",
    "    vals = np.abs(np.asarray(shap_values)).mean(axis=0)\n",
    "    return pd.Series(vals, index=feature_names)\n",
    "\n",
    "def _pos_index_from_model(model):\n",
    "    \"\"\"Try to map label '1' to its index in model.classes_. Defaults to 1 or last class.\"\"\"\n",
    "    try:\n",
    "        classes = getattr(model, \"classes_\", None)\n",
    "        if classes is not None:\n",
    "            classes = np.asarray(classes)\n",
    "            if 1 in classes:\n",
    "                return int(np.where(classes == 1)[0][0])\n",
    "            return int(np.argmax(classes))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 1\n",
    "\n",
    "def tree_shap(model, X_bg, X_eval, feature_names, positive_class_index=None):\n",
    "    \"\"\"\n",
    "    Robust Tree SHAP wrapper:\n",
    "    - Older SHAP: returns list [class0, class1]\n",
    "    - Newer SHAP: returns (n_samples, n_features) or (n_samples, n_features, n_classes)\n",
    "    \"\"\"\n",
    "    if positive_class_index is None:\n",
    "        positive_class_index = _pos_index_from_model(model)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model, data=X_bg)\n",
    "    sv = explainer.shap_values(X_eval)\n",
    "\n",
    "    # Older SHAP: list per class\n",
    "    if isinstance(sv, list):\n",
    "        if len(sv) > positive_class_index:\n",
    "            sv = sv[positive_class_index]\n",
    "        else:\n",
    "            sv = sv[-1]\n",
    "\n",
    "    sv = np.asarray(sv)\n",
    "    if sv.ndim == 3:\n",
    "        # (n_samples, n_features, n_classes)\n",
    "        if sv.shape[-1] > positive_class_index:\n",
    "            sv = sv[..., positive_class_index]\n",
    "        else:\n",
    "            sv = sv[..., -1]\n",
    "\n",
    "    return mean_abs_shap(sv, feature_names)\n",
    "\n",
    "def linear_shap_trained_lr_on_scaled(lr_estimator, X_bg_scaled, X_eval_scaled, feature_names):\n",
    "    \"\"\"\n",
    "    SHAP >=0.41: LinearExplainer(model, masker=shap.maskers.Independent(X_bg))\n",
    "    Older SHAP:  LinearExplainer(model, X_bg)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        masker = shap.maskers.Independent(X_bg_scaled)\n",
    "        explainer = shap.LinearExplainer(lr_estimator, masker=masker)\n",
    "        sv = explainer.shap_values(X_eval_scaled)\n",
    "    except TypeError:\n",
    "        # Fallback for older SHAP versions\n",
    "        explainer = shap.LinearExplainer(lr_estimator, X_bg_scaled)\n",
    "        sv = explainer.shap_values(X_eval_scaled)\n",
    "    return mean_abs_shap(sv, feature_names)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3) Normalization + composite\n",
    "# -----------------------------------------------------------\n",
    "def normalize_importance(s, how=\"sum1\"):\n",
    "    x = s.clip(lower=0).astype(float)\n",
    "    if how == \"sum1\":\n",
    "        denom = x.sum()\n",
    "        return (x / denom) if denom > 0 else x * 0.0\n",
    "    elif how == \"minmax\":\n",
    "        lo, hi = x.min(), x.max()\n",
    "        return (x - lo) / (hi - lo) if hi > lo else x * 0.0\n",
    "    else:\n",
    "        raise ValueError(\"how must be 'sum1' or 'minmax'\")\n",
    "\n",
    "def _flatten_model_columns(df):\n",
    "    \"\"\"\n",
    "    If concat created a MultiIndex on columns, drop to the top level (model names).\n",
    "    If it's already a simple Index, leave it as-is.\n",
    "    \"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        return df.copy().set_axis(df.columns.get_level_values(0), axis=1)\n",
    "    return df\n",
    "\n",
    "def composite_from_models(imp_dict, weights, scale=\"sum1\"):\n",
    "    # Align by feature index\n",
    "    df = pd.concat(imp_dict, axis=1)\n",
    "    df = _flatten_model_columns(df)  # <-- critical fix (no truncation of names)\n",
    "\n",
    "    # Normalize per-model importances\n",
    "    for m in df.columns:\n",
    "        df[m] = normalize_importance(df[m], how=scale)\n",
    "\n",
    "    # Normalize and align weights to columns safely\n",
    "    w_raw = pd.Series(weights, dtype=float)\n",
    "    w_norm = w_raw / w_raw.sum() if w_raw.sum() > 0 else pd.Series(1/len(w_raw), index=w_raw.index)\n",
    "    w_aligned = w_norm.reindex(df.columns).fillna(0.0)\n",
    "\n",
    "    comp = df.mul(w_aligned, axis=1).sum(axis=1)\n",
    "    out = df.copy()\n",
    "    out[\"CompositeImportance\"] = comp\n",
    "    out = out.sort_values(\"CompositeImportance\", ascending=False)\n",
    "    return out, w_aligned\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4) Sampling helpers for SHAP\n",
    "# -----------------------------------------------------------\n",
    "def sample_idx(n, k):\n",
    "    return rng.choice(n, size=min(k, n), replace=False)\n",
    "\n",
    "# ============================================================\n",
    "# >>> Your splits (already defined in your session) <<<\n",
    "# X_train_res_scaled, X_val_scaled, X_test_scaled\n",
    "# X_train, X_train_res, X_val, X_test\n",
    "# y_train, y_train_res, y_val, y_test\n",
    "# features\n",
    "# ============================================================\n",
    "\n",
    "# Coerce shapes/columns\n",
    "X_train_res_scaled = to_df(X_train_res_scaled, features)\n",
    "X_val_scaled       = to_df(X_val_scaled,       features)\n",
    "X_test_scaled      = to_df(X_test_scaled,      features)\n",
    "\n",
    "X_train     = to_df(X_train,     features)\n",
    "X_train_res = to_df(X_train_res, features)\n",
    "X_val       = to_df(X_val,       features)\n",
    "X_test      = to_df(X_test,      features)\n",
    "\n",
    "y_train     = to_series(y_train)\n",
    "y_train_res = to_series(y_train_res)\n",
    "y_val       = to_series(y_val)\n",
    "y_test      = to_series(y_test)\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5) Train models\n",
    "# -----------------------------------------------------------\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression (scaled, resampled)\n",
    "lr = LogisticRegression(max_iter=500, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "lr.fit(X_train_res_scaled, y_train_res)\n",
    "models[\"lr\"] = lr\n",
    "\n",
    "# Random Forest (unscaled, resampled)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "models[\"rf\"] = rf\n",
    "\n",
    "# XGBoost (optional, unscaled, resampled)\n",
    "if HAS_XGB:\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=700,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    xgb.fit(X_train_res, y_train_res)\n",
    "    models[\"xgb\"] = xgb\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6) Validation performance (for weights)\n",
    "# -----------------------------------------------------------\n",
    "def proba(model, X):\n",
    "    return model.predict_proba(X)[:, 1]\n",
    "\n",
    "perf = {\n",
    "    \"lr\":  perf_summary(y_val.values, proba(models[\"lr\"],  X_val_scaled)),\n",
    "    \"rf\":  perf_summary(y_val.values, proba(models[\"rf\"],  X_val)),\n",
    "}\n",
    "if \"xgb\" in models:\n",
    "    perf[\"xgb\"] = perf_summary(y_val.values, proba(models[\"xgb\"], X_val))\n",
    "\n",
    "perf_df = pd.DataFrame(perf).T\n",
    "print(\"Validation performance (weights source):\")\n",
    "print(perf_df[[\"roc_auc\", \"pr_auc\", \"ece\"]].round(4))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 7) SHAP computations (subsample for speed)\n",
    "# -----------------------------------------------------------\n",
    "bg_idx_lr = sample_idx(len(X_train_res_scaled), 200)\n",
    "ev_idx_lr = sample_idx(len(X_val_scaled), 300)\n",
    "bg_idx_tr = sample_idx(len(X_train_res), 200)\n",
    "ev_idx_tr = sample_idx(len(X_val), 300)\n",
    "\n",
    "imp = {}\n",
    "# LR SHAP on scaled data\n",
    "imp[\"lr\"] = linear_shap_trained_lr_on_scaled(\n",
    "    lr_estimator=models[\"lr\"],\n",
    "    X_bg_scaled=X_train_res_scaled.iloc[bg_idx_lr],\n",
    "    X_eval_scaled=X_val_scaled.iloc[ev_idx_lr],\n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "# RF SHAP on unscaled data (robust to 3D outputs)\n",
    "imp[\"rf\"] = tree_shap(\n",
    "    model=models[\"rf\"],\n",
    "    X_bg=X_train_res.iloc[bg_idx_tr],\n",
    "    X_eval=X_val.iloc[ev_idx_tr],\n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "# XGB SHAP (if available)\n",
    "if \"xgb\" in models:\n",
    "    imp[\"xgb\"] = tree_shap(\n",
    "        model=models[\"xgb\"],\n",
    "        X_bg=X_train_res.iloc[bg_idx_tr],\n",
    "        X_eval=X_val.iloc[ev_idx_tr],\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "\n",
    "imp_df = pd.DataFrame({m: s for m, s in imp.items()})\n",
    "imp_df.index.name = \"feature\"\n",
    "print(\"\\nPer-model mean(|SHAP|) (unnormalized) — head:\")\n",
    "print(imp_df.head(10).round(6))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 8) Build model weights (AUC-only by default; include (1-ECE) by setting beta=1.0)\n",
    "# -----------------------------------------------------------\n",
    "alpha, beta = 1.0, 0.0  # alpha: AUC exponent; beta: (1 - ECE) exponent\n",
    "weights = {}\n",
    "for m, met in perf.items():\n",
    "    auc = met[\"roc_auc\"]\n",
    "    ece = met[\"ece\"]\n",
    "    weights[m] = (auc ** alpha) * ((1 - ece) ** beta)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 9) Composite importance (robust column + weight alignment)\n",
    "# -----------------------------------------------------------\n",
    "comp_df, w_used = composite_from_models(imp, weights=weights, scale=\"sum1\")\n",
    "print(\"\\nModel weights used (normalized, aligned to columns):\")\n",
    "print(w_used.round(4))\n",
    "\n",
    "print(\"\\nTop features by CompositeImportance:\")\n",
    "print(comp_df.head(20).round(5))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 10) Test metrics (final reporting)\n",
    "# -----------------------------------------------------------\n",
    "test_metrics = {\n",
    "    \"lr\":  perf_summary(y_test.values, proba(models[\"lr\"],  X_test_scaled)),\n",
    "    \"rf\":  perf_summary(y_test.values, proba(models[\"rf\"],  X_test)),\n",
    "}\n",
    "if \"xgb\" in models:\n",
    "    test_metrics[\"xgb\"] = perf_summary(y_test.values, proba(models[\"xgb\"], X_test))\n",
    "\n",
    "print(\"\\nTest-set metrics:\")\n",
    "print(pd.DataFrame(test_metrics).T[[\"roc_auc\", \"pr_auc\", \"ece\"]].round(4))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 11) Optional exports\n",
    "# -----------------------------------------------------------\n",
    "# comp_df.to_csv(\"composite_importance.csv\")\n",
    "# imp_df.to_csv(\"per_model_mean_abs_shap.csv\")\n",
    "# perf_df.to_csv(\"validation_metrics_for_weights.csv\")\n",
    "# pd.DataFrame(test_metrics).T.to_csv(\"test_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930a02f-0b1a-4f03-a91e-81cac2936a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Multi-model SHAP + Composite Importance (magnitude + direction)\n",
    "# Models: LR, RF, XGB, MLP, TabNet, TabPFN\n",
    "# Handles TabPFN CPU >1000 samples safely (policy below)\n",
    "# Requires your pre-split objects in memory:\n",
    "# X_train_res_scaled, X_val_scaled, X_test_scaled,\n",
    "# X_train, X_train_res, X_val, X_test,\n",
    "# y_train, y_train_res, y_val, y_test, features\n",
    "# ============================================================\n",
    "\n",
    "import warnings, os, datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- TabPFN CPU policy: what to do if CPU & n_samples > 1000 ---\n",
    "# \"allow\"  -> set TABPFN_ALLOW_CPU_LARGE_DATASET=1 and proceed\n",
    "# \"subset\" -> train TabPFN on a random subset of size 1000\n",
    "# \"skip\"   -> skip TabPFN model\n",
    "TABPFN_POLICY = \"allow\"   # change to \"subset\" or \"skip\" if you prefer\n",
    "\n",
    "# Optional: silence tqdm's notebook warnings\n",
    "os.environ.setdefault(\"TQDM_DISABLE\", \"1\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "import torch, shap\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RANDOM_STATE = 42\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "# ---------- Config knobs ----------\n",
    "WEIGHT_BY = \"roc_auc\"        # \"roc_auc\" or \"pr_auc\"\n",
    "USE_CALIBRATION = False      # multiply weights by (1 - ECE)\n",
    "USE_STABILITY = False        # bootstrap stability into weights (runtime heavy)\n",
    "N_BOOT = 20\n",
    "TOPN_PLOT = 20\n",
    "OUTROOT = \"op/1_data_explore3/exports_preproc_dataset\"\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTDIR = os.path.join(OUTROOT, f\"composite_{TIMESTAMP}\")\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# SHAP sampling sizes\n",
    "TREE_BG_MAX = 200\n",
    "TREE_EV_MAX = 300\n",
    "LIN_BG_MAX  = 200\n",
    "LIN_EV_MAX  = 300\n",
    "KERNEL_BG_MAX = 120\n",
    "KERNEL_EV_MAX = 150\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def to_df(X, columns):\n",
    "    if isinstance(X, pd.DataFrame): return X.copy()\n",
    "    X = np.asarray(X)\n",
    "    if columns is None: columns = [f\"f{i}\" for i in range(X.shape[1])]\n",
    "    return pd.DataFrame(X, columns=columns)\n",
    "\n",
    "def to_series(y, name=\"target\"):\n",
    "    if isinstance(y, pd.Series): return y.copy()\n",
    "    return pd.Series(np.asarray(y).ravel(), name=name)\n",
    "\n",
    "def expected_calibration_error(y_true, y_prob, n_bins=15):\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    inds = np.digitize(y_prob, bins) - 1\n",
    "    ece = 0.0; N = len(y_true)\n",
    "    for b in range(n_bins):\n",
    "        mask = inds == b\n",
    "        if mask.sum() == 0: continue\n",
    "        conf = y_prob[mask].mean(); acc = y_true[mask].mean()\n",
    "        ece += (mask.sum()/N) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def perf_summary(y_true, y_prob):\n",
    "    return {\"roc_auc\": roc_auc_score(y_true, y_prob),\n",
    "            \"pr_auc\":  average_precision_score(y_true, y_prob),\n",
    "            \"ece\":     expected_calibration_error(y_true, y_prob, n_bins=15)}\n",
    "\n",
    "def mean_abs_shap(sv, feature_names):  return pd.Series(np.abs(np.asarray(sv)).mean(axis=0), index=feature_names)\n",
    "def mean_signed_shap(sv, feature_names): return pd.Series(np.asarray(sv).mean(axis=0), index=feature_names)\n",
    "\n",
    "def _pos_index_from_model(model):\n",
    "    try:\n",
    "        classes = getattr(model, \"classes_\", None)\n",
    "        if classes is not None:\n",
    "            classes = np.asarray(classes)\n",
    "            if 1 in classes: return int(np.where(classes == 1)[0][0])\n",
    "            return int(np.argmax(classes))\n",
    "    except Exception: pass\n",
    "    return 1\n",
    "\n",
    "def tree_shap(model, X_bg, X_eval, feature_names, signed=False, pos_idx=None):\n",
    "    if pos_idx is None: pos_idx = _pos_index_from_model(model)\n",
    "    explainer = shap.TreeExplainer(model, data=X_bg)\n",
    "    sv = explainer.shap_values(X_eval)\n",
    "    if isinstance(sv, list): sv = sv[pos_idx if len(sv)>pos_idx else -1]\n",
    "    sv = np.asarray(sv)\n",
    "    if sv.ndim == 3: sv = sv[..., pos_idx if sv.shape[-1]>pos_idx else -1]\n",
    "    return (mean_signed_shap if signed else mean_abs_shap)(sv, feature_names)\n",
    "\n",
    "def linear_shap_lr(lr, X_bg_scaled, X_eval_scaled, feature_names, signed=False):\n",
    "    try:\n",
    "        explainer = shap.LinearExplainer(lr, masker=shap.maskers.Independent(X_bg_scaled))\n",
    "        sv = explainer.shap_values(X_eval_scaled)\n",
    "    except TypeError:\n",
    "        explainer = shap.LinearExplainer(lr, X_bg_scaled)\n",
    "        sv = explainer.shap_values(X_eval_scaled)\n",
    "    return (mean_signed_shap if signed else mean_abs_shap)(sv, feature_names)\n",
    "\n",
    "def kernel_shap_from_proba(predict_proba_fn, X_bg_np, X_eval_np, feature_names, signed=False):\n",
    "    explainer = shap.KernelExplainer(lambda X: predict_proba_fn(X)[:, 1], X_bg_np)\n",
    "    sv = explainer.shap_values(X_eval_np, nsamples=\"auto\")\n",
    "    return (mean_signed_shap if signed else mean_abs_shap)(np.asarray(sv), feature_names)\n",
    "\n",
    "def normalize_importance(s, how=\"sum1\"):\n",
    "    x = s.astype(float)\n",
    "    if how == \"sum1\":\n",
    "        x = x.clip(lower=0); denom = x.sum()\n",
    "        return (x/denom) if denom>0 else x*0.0\n",
    "    elif how == \"minmax\":\n",
    "        lo, hi = x.min(), x.max()\n",
    "        return (x-lo)/(hi-lo) if hi>lo else x*0.0\n",
    "    else:\n",
    "        raise ValueError(\"how must be 'sum1' or 'minmax'\")\n",
    "\n",
    "def _flatten_model_columns(df):\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        return df.set_axis(df.columns.get_level_values(0), axis=1)\n",
    "    return df\n",
    "\n",
    "def composite_from_models(imp_mag_dict, weights, scale=\"sum1\", signed_dict=None):\n",
    "    df_mag = _flatten_model_columns(pd.concat(imp_mag_dict, axis=1))\n",
    "    for m in df_mag.columns: df_mag[m] = normalize_importance(df_mag[m], how=scale)\n",
    "    w_raw = pd.Series(weights, dtype=float)\n",
    "    w_norm = (w_raw / w_raw.sum()) if w_raw.sum()>0 else pd.Series(1/len(w_raw), index=w_raw.index)\n",
    "    w_aligned = w_norm.reindex(df_mag.columns).fillna(0.0)\n",
    "    comp_mag = df_mag.mul(w_aligned, axis=1).sum(axis=1)\n",
    "\n",
    "    out = df_mag.copy(); out[\"CompositeImportance\"] = comp_mag\n",
    "    if signed_dict:\n",
    "        df_signed = _flatten_model_columns(pd.concat(signed_dict, axis=1))\n",
    "        w_signed = w_norm.reindex(df_signed.columns).fillna(0.0)\n",
    "        comp_signed = df_signed.mul(w_signed, axis=1).sum(axis=1)\n",
    "        out[\"CompositeSigned\"] = comp_signed\n",
    "        out[\"CompositeSign\"] = np.sign(comp_signed).replace({0.0: 0.0})\n",
    "    else:\n",
    "        out[\"CompositeSigned\"] = np.nan; out[\"CompositeSign\"] = np.nan\n",
    "\n",
    "    return out.sort_values(\"CompositeImportance\", ascending=False), w_aligned\n",
    "\n",
    "def sample_idx(n, k): return rng.choice(n, size=min(k, n), replace=False)\n",
    "\n",
    "def plot_topn(series, title, outpath, topn=20):\n",
    "    s = series.sort_values(ascending=False).head(topn)[::-1]\n",
    "    plt.figure(figsize=(8, max(4, topn*0.35))); plt.barh(s.index, s.values)\n",
    "    plt.title(title); plt.tight_layout(); plt.savefig(outpath, dpi=150); plt.close()\n",
    "\n",
    "# ---------- Bring in your data ----------\n",
    "X_train_res_scaled = to_df(X_train_res_scaled, features)\n",
    "X_val_scaled       = to_df(X_val_scaled,       features)\n",
    "X_test_scaled      = to_df(X_test_scaled,      features)\n",
    "X_train     = to_df(X_train,     features)\n",
    "X_train_res = to_df(X_train_res, features)\n",
    "X_val       = to_df(X_val,       features)\n",
    "X_test      = to_df(X_test,      features)\n",
    "y_train     = to_series(y_train)\n",
    "y_train_res = to_series(y_train_res)\n",
    "y_val       = to_series(y_val)\n",
    "y_test      = to_series(y_test)\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "# ---------- Train models ----------\n",
    "models = {}\n",
    "lr = LogisticRegression(max_iter=500, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "lr.fit(X_train_res_scaled, y_train_res); models[\"lr\"] = lr\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=600, max_depth=None, max_features=\"sqrt\",\n",
    "                            class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE)\n",
    "rf.fit(X_train_res, y_train_res); models[\"rf\"] = rf\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=700, learning_rate=0.05, max_depth=5,\n",
    "                    subsample=0.9, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "                    objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "                    random_state=RANDOM_STATE, n_jobs=-1, tree_method=\"hist\")\n",
    "xgb.fit(X_train_res, y_train_res); models[\"xgb\"] = xgb\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128,64), activation=\"relu\", solver=\"adam\",\n",
    "                    alpha=1e-4, learning_rate_init=1e-3, max_iter=200,\n",
    "                    early_stopping=True, random_state=RANDOM_STATE)\n",
    "mlp.fit(X_train_res_scaled, y_train_res); models[\"mlp\"] = mlp\n",
    "\n",
    "tn = TabNetClassifier(seed=RANDOM_STATE, verbose=0, device_name=DEVICE)\n",
    "tn.fit(X_train_res.values, y_train_res.values,\n",
    "       eval_set=[(X_val.values, y_val.values)], eval_name=[\"val\"],\n",
    "       patience=10, max_epochs=50, batch_size=1024, virtual_batch_size=128)\n",
    "models[\"tabnet\"] = tn\n",
    "\n",
    "# --- TabPFN safe fit (handles CPU >1000) ---\n",
    "def fit_tabpfn_safe(X_np, y_np, policy=\"allow\"):\n",
    "    n = X_np.shape[0]\n",
    "    if torch.cuda.is_available():\n",
    "        clf = TabPFNClassifier(device=\"cuda\", random_state=RANDOM_STATE)\n",
    "        clf.fit(X_np, y_np); return clf\n",
    "    # CPU path\n",
    "    if n > 1000:\n",
    "        if policy == \"allow\":\n",
    "            os.environ[\"TABPFN_ALLOW_CPU_LARGE_DATASET\"] = \"1\"\n",
    "            clf = TabPFNClassifier(device=\"cpu\", random_state=RANDOM_STATE)\n",
    "            clf.fit(X_np, y_np); return clf\n",
    "        elif policy == \"subset\":\n",
    "            idx = rng.choice(n, size=1000, replace=False)\n",
    "            clf = TabPFNClassifier(device=\"cpu\", random_state=RANDOM_STATE)\n",
    "            clf.fit(X_np[idx], y_np[idx]); return clf\n",
    "        elif policy == \"skip\":\n",
    "            return None\n",
    "        else:\n",
    "            raise ValueError(\"TABPFN_POLICY must be 'allow', 'subset', or 'skip'\")\n",
    "    # n <= 1000 -> safe on CPU\n",
    "    clf = TabPFNClassifier(device=\"cpu\", random_state=RANDOM_STATE)\n",
    "    clf.fit(X_np, y_np); return clf\n",
    "\n",
    "tpf = fit_tabpfn_safe(X_train_res.values, y_train_res.values, policy=TABPFN_POLICY)\n",
    "if tpf is not None: models[\"tabpfn\"] = tpf\n",
    "else: print(\"[TabPFN] Skipped per policy\")\n",
    "\n",
    "# ---------- Validation performance (weights) ----------\n",
    "def proba(model, X):\n",
    "    if isinstance(model, TabNetClassifier) or isinstance(model, TabPFNClassifier):\n",
    "        return model.predict_proba(X.values if isinstance(X, pd.DataFrame) else X)\n",
    "    return model.predict_proba(X)\n",
    "\n",
    "perf = {\n",
    "    \"lr\":     perf_summary(y_val.values, proba(models[\"lr\"],     X_val_scaled)[:,1]),\n",
    "    \"rf\":     perf_summary(y_val.values, proba(models[\"rf\"],     X_val)[:,1]),\n",
    "    \"xgb\":    perf_summary(y_val.values, proba(models[\"xgb\"],    X_val)[:,1]),\n",
    "    \"mlp\":    perf_summary(y_val.values, proba(models[\"mlp\"],    X_val_scaled)[:,1]),\n",
    "    \"tabnet\": perf_summary(y_val.values, proba(models[\"tabnet\"], X_val)[:,1]),\n",
    "}\n",
    "if \"tabpfn\" in models:\n",
    "    perf[\"tabpfn\"] = perf_summary(y_val.values, proba(models[\"tabpfn\"], X_val)[:,1])\n",
    "\n",
    "perf_df = pd.DataFrame(perf).T\n",
    "print(\"Validation performance (weights source):\")\n",
    "print(perf_df[[\"roc_auc\",\"pr_auc\",\"ece\"]].round(4))\n",
    "\n",
    "# ---------- SHAP (magnitude + signed) ----------\n",
    "bg_idx_lin  = sample_idx(len(X_train_res_scaled), LIN_BG_MAX)\n",
    "ev_idx_lin  = sample_idx(len(X_val_scaled),      LIN_EV_MAX)\n",
    "bg_idx_tree = sample_idx(len(X_train_res), TREE_BG_MAX)\n",
    "ev_idx_tree = sample_idx(len(X_val),      TREE_EV_MAX)\n",
    "\n",
    "imp_mag, imp_signed = {}, {}\n",
    "\n",
    "# LR (scaled)\n",
    "imp_mag[\"lr\"]    = linear_shap_lr(lr, X_train_res_scaled.iloc[bg_idx_lin], X_val_scaled.iloc[ev_idx_lin], feature_names, signed=False)\n",
    "imp_signed[\"lr\"] = linear_shap_lr(lr, X_train_res_scaled.iloc[bg_idx_lin], X_val_scaled.iloc[ev_idx_lin], feature_names, signed=True)\n",
    "\n",
    "# RF, XGB (unscaled)\n",
    "imp_mag[\"rf\"]    = tree_shap(rf,  X_train_res.iloc[bg_idx_tree], X_val.iloc[ev_idx_tree], feature_names, signed=False)\n",
    "imp_signed[\"rf\"] = tree_shap(rf,  X_train_res.iloc[bg_idx_tree], X_val.iloc[ev_idx_tree], feature_names, signed=True)\n",
    "imp_mag[\"xgb\"]    = tree_shap(xgb, X_train_res.iloc[bg_idx_tree], X_val.iloc[ev_idx_tree], feature_names, signed=False)\n",
    "imp_signed[\"xgb\"] = tree_shap(xgb, X_train_res.iloc[bg_idx_tree], X_val.iloc[ev_idx_tree], feature_names, signed=True)\n",
    "\n",
    "# MLP (scaled) -> Kernel SHAP\n",
    "bg_idx_ker = sample_idx(len(X_train_res_scaled), KERNEL_BG_MAX)\n",
    "ev_idx_ker = sample_idx(len(X_val_scaled),      KERNEL_EV_MAX)\n",
    "X_bg_mlp = X_train_res_scaled.iloc[bg_idx_ker].values\n",
    "X_ev_mlp = X_val_scaled.iloc[ev_idx_ker].values\n",
    "imp_mag[\"mlp\"]    = kernel_shap_from_proba(lambda Z: mlp.predict_proba(Z), X_bg_mlp, X_ev_mlp, feature_names, signed=False)\n",
    "imp_signed[\"mlp\"] = kernel_shap_from_proba(lambda Z: mlp.predict_proba(Z), X_bg_mlp, X_ev_mlp, feature_names, signed=True)\n",
    "\n",
    "# TabNet (unscaled) -> Kernel SHAP\n",
    "X_bg_tn = X_train_res.iloc[sample_idx(len(X_train_res), KERNEL_BG_MAX)].values\n",
    "X_ev_tn = X_val.iloc[sample_idx(len(X_val), KERNEL_EV_MAX)].values\n",
    "imp_mag[\"tabnet\"]    = kernel_shap_from_proba(lambda Z: tn.predict_proba(Z), X_bg_tn, X_ev_tn, feature_names, signed=False)\n",
    "imp_signed[\"tabnet\"] = kernel_shap_from_proba(lambda Z: tn.predict_proba(Z), X_bg_tn, X_ev_tn, feature_names, signed=True)\n",
    "\n",
    "# TabPFN (unscaled) -> Kernel SHAP (only if trained)\n",
    "if \"tabpfn\" in models:\n",
    "    X_bg_tp = X_train_res.iloc[sample_idx(len(X_train_res), KERNEL_BG_MAX)].values\n",
    "    X_ev_tp = X_val.iloc[sample_idx(len(X_val), KERNEL_EV_MAX)].values\n",
    "    imp_mag[\"tabpfn\"]    = kernel_shap_from_proba(lambda Z: models[\"tabpfn\"].predict_proba(Z), X_bg_tp, X_ev_tp, feature_names, signed=False)\n",
    "    imp_signed[\"tabpfn\"] = kernel_shap_from_proba(lambda Z: models[\"tabpfn\"].predict_proba(Z), X_bg_tp, X_ev_tp, feature_names, signed=True)\n",
    "\n",
    "# ---------- Optional stability (off by default) ----------\n",
    "stability = {}\n",
    "if USE_STABILITY:\n",
    "    print(\"Computing stability weights (bootstrap)...\")\n",
    "    stability[\"lr\"]     = 1.0  # (skip bootstrap for brevity or implement like earlier)\n",
    "    # You can paste the earlier bootstrap function calls here if needed.\n",
    "\n",
    "# ---------- Build weights ----------\n",
    "weights = {}\n",
    "for m, met in perf.items():\n",
    "    w = max(met[WEIGHT_BY], 1e-8)\n",
    "    if USE_CALIBRATION: w *= (1.0 - met[\"ece\"])\n",
    "    if USE_STABILITY and m in stability: w *= max(stability[m], 1e-6)\n",
    "    weights[m] = w\n",
    "\n",
    "w_series = pd.Series(weights, name=\"weight\"); w_series = w_series / w_series.sum()\n",
    "print(\"\\nModel weights used (normalized):\"); print(w_series.round(4))\n",
    "\n",
    "# ---------- Composite ----------\n",
    "comp_df, w_used = composite_from_models(imp_mag, weights=w_series.to_dict(), scale=\"sum1\", signed_dict=imp_signed)\n",
    "print(\"\\nTop features by CompositeImportance:\"); print(comp_df.head(20).round(5))\n",
    "\n",
    "# ---------- Test metrics ----------\n",
    "def proba_np(model, X):\n",
    "    if isinstance(model, TabNetClassifier) or isinstance(model, TabPFNClassifier):\n",
    "        return model.predict_proba(X.values if isinstance(X, pd.DataFrame) else X)\n",
    "    return model.predict_proba(X)\n",
    "\n",
    "test_metrics = {\n",
    "    \"lr\":     perf_summary(y_test.values, proba_np(lr,     X_test_scaled)[:,1]),\n",
    "    \"rf\":     perf_summary(y_test.values, proba_np(rf,     X_test)[:,1]),\n",
    "    \"xgb\":    perf_summary(y_test.values, proba_np(xgb,    X_test)[:,1]),\n",
    "    \"mlp\":    perf_summary(y_test.values, proba_np(mlp,    X_test_scaled)[:,1]),\n",
    "    \"tabnet\": perf_summary(y_test.values, proba_np(tn,     X_test)[:,1]),\n",
    "}\n",
    "if \"tabpfn\" in models:\n",
    "    test_metrics[\"tabpfn\"] = perf_summary(y_test.values, proba_np(models[\"tabpfn\"], X_test)[:,1])\n",
    "\n",
    "test_df = pd.DataFrame(test_metrics).T[[\"roc_auc\",\"pr_auc\",\"ece\"]]\n",
    "print(\"\\nTest-set metrics:\"); print(test_df.round(4))\n",
    "\n",
    "# ---------- Exports ----------\n",
    "pd.DataFrame(imp_mag).to_csv(os.path.join(OUTDIR, \"per_model_mean_abs_shap.csv\"))\n",
    "pd.DataFrame(imp_signed).to_csv(os.path.join(OUTDIR, \"per_model_mean_signed_shap.csv\"))\n",
    "comp_df.to_csv(os.path.join(OUTDIR, \"composite_importance.csv\"))\n",
    "perf_df.to_csv(os.path.join(OUTDIR, \"validation_metrics_for_weights.csv\"))\n",
    "w_series.to_csv(os.path.join(OUTDIR, \"model_weights.csv\"))\n",
    "test_df.to_csv(os.path.join(OUTDIR, \"test_metrics.csv\"))\n",
    "\n",
    "def plot_topn(series, title, outpath, topn=20):\n",
    "    s = series.sort_values(ascending=False).head(topn)[::-1]\n",
    "    plt.figure(figsize=(8, max(4, topn*0.35))); plt.barh(s.index, s.values)\n",
    "    plt.title(title); plt.tight_layout(); plt.savefig(outpath, dpi=150); plt.close()\n",
    "\n",
    "plot_topn(comp_df[\"CompositeImportance\"], \"Top Composite Importance (magnitude)\",\n",
    "          os.path.join(OUTDIR, \"top_composite_importance.png\"), topn=TOPN_PLOT)\n",
    "plot_topn(comp_df[\"CompositeSigned\"].abs(), \"Top Composite |Signed| (magnitude only)\",\n",
    "          os.path.join(OUTDIR, \"top_composite_signed_abs.png\"), topn=TOPN_PLOT)\n",
    "\n",
    "print(f\"\\nArtifacts saved to: {OUTDIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf8b18-bf21-49bf-823c-c9da60fe0b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec471d3-db45-4126-bf0a-9c7b70d96d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (hints6_v0)",
   "language": "python",
   "name": "hints6_v0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
